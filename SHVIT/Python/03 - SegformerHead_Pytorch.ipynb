{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgd/anaconda3/envs/shvit/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from mmcv.cnn import ConvModule, DepthwiseSeparableConvModule\n",
    "from collections import OrderedDict\n",
    "\n",
    "# from mmseg.ops import resize\n",
    "# from ..builder import HEADS\n",
    "# from .decode_head import BaseDecodeHead\n",
    "# from mmseg.models.utils import *\n",
    "# import attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(input,\n",
    "           size=None,\n",
    "           scale_factor=None,\n",
    "           mode='nearest',\n",
    "           align_corners=None,\n",
    "           warning=True):\n",
    "    if warning:\n",
    "        if size is not None and align_corners:\n",
    "            input_h, input_w = tuple(int(x) for x in input.shape[2:])\n",
    "            output_h, output_w = tuple(int(x) for x in size)\n",
    "            if output_h > input_h or output_w > output_h:\n",
    "                if ((output_h > 1 and output_w > 1 and input_h > 1\n",
    "                     and input_w > 1) and (output_h - 1) % (input_h - 1)\n",
    "                        and (output_w - 1) % (input_w - 1)):\n",
    "                    warnings.warn(\n",
    "                        f'When align_corners={align_corners}, '\n",
    "                        'the output would more aligned if '\n",
    "                        f'input size {(input_h, input_w)} is `x+1` and '\n",
    "                        f'out size {(output_h, output_w)} is `nx+1`')\n",
    "    if isinstance(size, torch.Size):\n",
    "        size = tuple(int(x) for x in size)\n",
    "    return F.interpolate(input, size, scale_factor, mode, align_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=2048, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(input_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseDecodeHead' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSegFormerHead\u001b[39;00m(\u001b[43mBaseDecodeHead\u001b[49m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, feature_strides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseDecodeHead' is not defined"
     ]
    }
   ],
   "source": [
    "class SegFormerHead(BaseDecodeHead):\n",
    "    \"\"\"\n",
    "    SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_strides, **kwargs):\n",
    "        super(SegFormerHead, self).__init__(input_transform='multiple_select', **kwargs)\n",
    "        assert len(feature_strides) == len(self.in_channels)\n",
    "        assert min(feature_strides) == feature_strides[0]\n",
    "        self.feature_strides = feature_strides\n",
    "\n",
    "        c1_in_channels, c2_in_channels, c3_in_channels, c4_in_channels = self.in_channels\n",
    "        print(\"c1_in_channels, c2_in_channels, c3_in_channels, c4_in_channels\")\n",
    "        print(\"==============================================================\")\n",
    "        print(c1_in_channels, c2_in_channels, c3_in_channels, c4_in_channels)\n",
    "\n",
    "        decoder_params = kwargs['decoder_params']\n",
    "        embedding_dim = decoder_params['embed_dim']\n",
    "\n",
    "        self.linear_c4 = MLP(input_dim=c4_in_channels, embed_dim=embedding_dim)\n",
    "        self.linear_c3 = MLP(input_dim=c3_in_channels, embed_dim=embedding_dim)\n",
    "        self.linear_c2 = MLP(input_dim=c2_in_channels, embed_dim=embedding_dim)\n",
    "        self.linear_c1 = MLP(input_dim=c1_in_channels, embed_dim=embedding_dim)\n",
    "\n",
    "        self.linear_fuse = ConvModule(\n",
    "            in_channels=embedding_dim*4,\n",
    "            out_channels=embedding_dim,\n",
    "            kernel_size=1,\n",
    "            norm_cfg=dict(type='SyncBN', requires_grad=True)\n",
    "        )\n",
    "\n",
    "        self.linear_pred = nn.Conv2d(embedding_dim, self.num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self._transform_inputs(inputs)  # len=4, 1/4,1/8,1/16,1/32\n",
    "        c1, c2, c3, c4 = x\n",
    "\n",
    "        ############## MLP decoder on C1-C4 ###########\n",
    "        n, _, h, w = c4.shape\n",
    "\n",
    "        _c4 = self.linear_c4(c4).permute(0,2,1).reshape(n, -1, c4.shape[2], c4.shape[3])\n",
    "        _c4 = resize(_c4, size=c1.size()[2:],mode='bilinear',align_corners=False)\n",
    "\n",
    "        _c3 = self.linear_c3(c3).permute(0,2,1).reshape(n, -1, c3.shape[2], c3.shape[3])\n",
    "        _c3 = resize(_c3, size=c1.size()[2:],mode='bilinear',align_corners=False)\n",
    "\n",
    "        _c2 = self.linear_c2(c2).permute(0,2,1).reshape(n, -1, c2.shape[2], c2.shape[3])\n",
    "        _c2 = resize(_c2, size=c1.size()[2:],mode='bilinear',align_corners=False)\n",
    "\n",
    "        _c1 = self.linear_c1(c1).permute(0,2,1).reshape(n, -1, c1.shape[2], c1.shape[3])\n",
    "\n",
    "        _c = self.linear_fuse(torch.cat([_c4, _c3, _c2, _c1], dim=1))\n",
    "\n",
    "        x = self.dropout(_c)\n",
    "        x = self.linear_pred(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
