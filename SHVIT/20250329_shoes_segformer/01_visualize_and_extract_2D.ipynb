{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# from zipfile import ZipFile\n",
    "# path = \"./PythonTools-3.7.0-py2.py3-none-any.whl\"\n",
    "# names = ZipFile(path).namelist()\n",
    "# pprint.pprint(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import slicerio # https://pypi.org/project/slicerio/\n",
    "\n",
    "from PythonTools.rek2py import rek2py\n",
    "# from PythonTools.raw2dicom import raw2dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPictures(folderpath, filename, volume):\n",
    "\n",
    "    n_row, n_col = 5, 5\n",
    "\n",
    "    # Define the folder path and check if folder exists, if not, create it\n",
    "    folder_path = Path(folderpath)\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    imagelist = volume/255 # von der Seite\n",
    "    step = (imagelist.shape[0]-1)/24\n",
    "    print(imagelist.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(n_row, n_col, figsize=(9, 9), dpi=300)\n",
    "    fig.suptitle(f\"{filename} - Volume Slices\", fontsize=16)\n",
    "    for idx in range(n_row*n_col):\n",
    "        ax.ravel()[idx].imshow(imagelist[int(idx*step)], cmap=\"gray\")\n",
    "        ax.ravel()[idx].set_axis_off()\n",
    "        if filename in [\"Background\"]:\n",
    "            ax.ravel()[idx].text(100,75,f\"Layer: {int(idx*step)}\", color=\"black\", fontsize=8)\n",
    "        else:\n",
    "            ax.ravel()[idx].text(100,75,f\"Layer: {int(idx*step)}\", color=\"white\", fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{folder_path.joinpath(filename)}.png\", dpi=300)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_files(directory, ext):\n",
    "\n",
    "    directory_path = Path(directory)\n",
    "    # List all files in the directory and subdirectories\n",
    "    all_files = list(directory_path.rglob(ext))  \n",
    "\n",
    "    # Filter out directories\n",
    "    files = [file for file in all_files if file.is_file()]\n",
    "    return files\n",
    "\n",
    "\n",
    "# Example usage\n",
    "directory = \"./Data/volumes/\"\n",
    "files = list_all_files(directory, \"*.rek\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after run check how shoes are oriented in the box; repeat only the files where shoes are not displayed from the side - modify transpose\n",
    "rotate_shoes = [\"./Data/volumes/Adidas_Martin.rek\",\"./Data/volumes/Citywalk-sit-taupe-34_down2_2_2.rek\", \n",
    "                \"./Data/volumes/Citywalk-sit-taupe-36_down2_2_2.rek\", \"./Data/volumes/Citywalk-sit-taupe-40_down2_2_2.rek\", \n",
    "                \"./Data/volumes/Schuh_Martin_down2_2_2.rek\", \"./Data/volumes/Sneaker_Dana_Nike.rek\",\n",
    "                \"./Data/volumes/Sneaker_Dana_Puma_Flyer.rek\"]\n",
    "\n",
    "# Convert to pathlib.Path objects\n",
    "rotate_shoes = [Path(folder) for folder in rotate_shoes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = \"./images/shoes_side_2D_25_layers_5x5\"\n",
    "\n",
    "print(files)\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    # Get the file name without extension\n",
    "    file_path  = Path(file)\n",
    "    filename =  file_path.stem\n",
    "    print(filename)\n",
    "\n",
    "    # dicomdata = raw2dicom(image=volume, ezrt_header=header)\n",
    "    header, volume = rek2py(filepath=file, switch_order=True)\n",
    "    print(volume.shape)\n",
    "  \n",
    "    # createAnimation(filename, volume)\n",
    "    if file in rotate_shoes:\n",
    "        orientation = (1,2,0)\n",
    "    else:\n",
    "        orientation = (2,1,0)\n",
    "    \n",
    "    plotPictures(target_directory, filename, volume.transpose(orientation)) # these shoes need different orientation / transpose      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./Data/annotations/Bruschi_down2_2_2.seg.nrrd\"\n",
    "\n",
    "segmentation = slicerio.read_segmentation(filepath, skip_voxels=True)\n",
    "\n",
    "number_of_segments = len(segmentation[\"segments\"])\n",
    "print(f\"Number of segments: {number_of_segments}\")\n",
    "\n",
    "segment_names = slicerio.segment_names(segmentation)\n",
    "print(f\"Segment names: {', '.join(segment_names)}\")\n",
    "\n",
    "#segment0 = slicerio.segment_from_name(segmentation, segment_names[0])\n",
    "#print(\"First segment info:\\n\" + json.dumps(segment0, sort_keys=False, indent=4))\n",
    "\n",
    "\n",
    "for k in range(number_of_segments):\n",
    "    seg = slicerio.segment_from_name(segmentation, segment_names[k])\n",
    "    print(f\"{k+1} segment info:\\n\" + json.dumps(seg, sort_keys=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./Data/annotations/\"\n",
    "files = list_all_files(directory, \"*.seg.nrrd\")\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    # Get the file name without extension\n",
    "    file_path  = Path(file)\n",
    "    filename =  file_path.stem\n",
    "    print(filename)    \n",
    "\n",
    "    segmentation = slicerio.read_segmentation(str(file), skip_voxels=True)\n",
    "\n",
    "    number_of_segments = len(segmentation[\"segments\"])\n",
    "    print(f\"Number of segments: {number_of_segments}\")\n",
    "\n",
    "    segment_names = slicerio.segment_names(segmentation)\n",
    "    print(f\"Segment names: {', '.join(segment_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code for numbering using '.seg.nrrd' of 3D Slicer\n",
    "\n",
    "filepath = \"./Data/annotations/Bruschi_down2_2_2.seg.nrrd\"\n",
    "segmentation_info = slicerio.read_segmentation(filepath)\n",
    "segment_names = slicerio.segment_names(segmentation_info) # Get semgnet_names where 3D Slicer\n",
    "\n",
    "dict_label = {}\n",
    "segment_names_to_labels = []\n",
    "for j, sn in enumerate(segment_names):\n",
    "    segment_names_to_labels.append((sn, j+1)) \n",
    "    if not segment_names_to_labels:\n",
    "        continue\n",
    "    \n",
    "print(segment_names_to_labels)\n",
    "\n",
    "#segment_names_to_labels = [('Schuh_1', 2), ('Schuh_2', 3)]\n",
    "\n",
    "# Numbering according to Segmented labels of 3D Slicer\n",
    "data = slicerio.extract_segments(segmentation_info, segment_names_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.get(\"voxels\")\n",
    "print(a.shape)\n",
    "print(np.unique(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[('Background', 1), ('Schuh_1', 2), ('Schuh_2', 3), ('Karton', 4), ('Innenvolumen_1', 5), ('Innenvolumen_2', 6), ('Obermaterial', 7), ('Innensohle', 8), ('Auensohle', 9), ('Fllmaterial', 10), ('Zunge', 11), ('Dummyschuh', 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Background     = slicerio.extract_segments(segmentation_info, [('Background', 1)])\n",
    "data_Schuh_1        = slicerio.extract_segments(segmentation_info, [('Schuh_1', 2)])\n",
    "data_Schuh_2        = slicerio.extract_segments(segmentation_info, [('Schuh_2', 3)])\n",
    "data_Karton         = slicerio.extract_segments(segmentation_info, [('Karton', 4)])\n",
    "data_Innenvolumen_1 = slicerio.extract_segments(segmentation_info, [('Innenvolumen_1', 5)])\n",
    "data_Innenvolumen_2 = slicerio.extract_segments(segmentation_info, [('Innenvolumen_2', 6)])\n",
    "data_Obermaterial   = slicerio.extract_segments(segmentation_info, [('Obermaterial', 7)])\n",
    "data_Innensohle     = slicerio.extract_segments(segmentation_info, [('Innensohle', 8)])\n",
    "data_Aussensohle    = slicerio.extract_segments(segmentation_info, [('Auensohle', 9)])\n",
    "data_Fuellmaterial  = slicerio.extract_segments(segmentation_info, [('Fllmaterial', 10)])\n",
    "data_Zunge          = slicerio.extract_segments(segmentation_info, [('Zunge', 11)])\n",
    "data_Dummyschuh     = slicerio.extract_segments(segmentation_info, [('Dummyschuh', 12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(data_Background.get(\"voxels\")))\n",
    "# print(np.unique(data_Schuh_1.get(\"voxels\")))\n",
    "# print(np.unique(data_Schuh_2.get(\"voxels\")))\n",
    "# print(np.unique(data_Karton.get(\"voxels\")))\n",
    "# print(np.unique(data_Innenvolumen_1.get(\"voxels\")))\n",
    "# print(np.unique(data_Innenvolumen_2.get(\"voxels\")))\n",
    "# print(np.unique(data_Obermaterial.get(\"voxels\")))\n",
    "# print(np.unique(data_Innensohle.get(\"voxels\")))\n",
    "# print(np.unique(data_Aussensohle.get(\"voxels\")))\n",
    "# print(np.unique(data_Fuellmaterial.get(\"voxels\")))\n",
    "# print(np.unique(data_Zunge.get(\"voxels\")))\n",
    "# print(np.unique(data_Dummyschuh.get(\"voxels\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = \"./images/masks_Bruschi_down2_2_2_side_2D_25_layers_5x5\"\n",
    "\n",
    "orientation = (0,1,2)\n",
    "\n",
    "plotPictures(target_directory, \"Background\", data_Background.get(\"voxels\").transpose(orientation)*255/1)\n",
    "plotPictures(target_directory, \"Schuh_1\", data_Schuh_1.get(\"voxels\").transpose(orientation)*255/2)\n",
    "plotPictures(target_directory, \"Schuh_2\", data_Schuh_2.get(\"voxels\").transpose(orientation)*255/3)\n",
    "plotPictures(target_directory, \"Karton\", data_Karton.get(\"voxels\").transpose(orientation)*255/4)\n",
    "plotPictures(target_directory, \"Innenvolumen_1\", data_Innenvolumen_1.get(\"voxels\").transpose(orientation)*255/5)\n",
    "plotPictures(target_directory, \"Innenvolumen_2\", data_Innenvolumen_2.get(\"voxels\").transpose(orientation)*255/6)\n",
    "plotPictures(target_directory, \"Obermaterial\", data_Obermaterial.get(\"voxels\").transpose(orientation)*255/7)\n",
    "plotPictures(target_directory, \"Innensohle\", data_Innensohle.get(\"voxels\").transpose(orientation)*255/8)\n",
    "plotPictures(target_directory, \"Außensohle\", data_Aussensohle.get(\"voxels\").transpose(orientation)*255/9)\n",
    "plotPictures(target_directory, \"Füllmaterial\", data_Fuellmaterial.get(\"voxels\").transpose(orientation)*255/10)\n",
    "plotPictures(target_directory, \"Zunge\", data_Zunge.get(\"voxels\").transpose(orientation)*255/11)\n",
    "plotPictures(target_directory, \"Dummyschuh\", data_Dummyschuh.get(\"voxels\").transpose(orientation)*255/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinePictures(folderpath, filename, volume):\n",
    "\n",
    "    n_row, n_col = 4, 3\n",
    "\n",
    "    # Define the folder path and check if folder exists, if not, create it\n",
    "    folder_path = Path(folderpath)\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    imagelist = volume # von der Seite\n",
    "    print(imagelist.shape)\n",
    "\n",
    "    layer = [\"Background\", \"Schuh_1\", \"Schuh_2\", \"Karton\", \"Innenvolumen_1\", \"Innenvolumen_2\", \"Obermaterial\", \"Innensohle\", \"Außensohle\", \"Füllmaterial\", \"Zunge\", \"Dummyschuh\"]\n",
    "\n",
    "\n",
    "    _, ax = plt.subplots(n_row, n_col, figsize=(9, 9), dpi=300)\n",
    "    for idx in range(n_row*n_col):\n",
    "        ax.ravel()[idx].imshow(imagelist[idx], cmap=\"gray\")\n",
    "        ax.ravel()[idx].set_axis_off()\n",
    "        if idx==0: # idx for Background\n",
    "            ax.ravel()[idx].text(50,50,f\"{layer[idx]}\", color=\"black\", fontsize=10)\n",
    "        else:\n",
    "            ax.ravel()[idx].text(50,50,f\"{layer[idx]}\", color=\"white\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{folder_path.joinpath(filename)}.png\", dpi=300)    \n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only layer 335 and combine to one image\n",
    "target_directory = \"./images/masks_Bruschi_down2_2_2_side_2D_25_layers_5x5\"\n",
    "\n",
    "_Background = data_Background.get(\"voxels\")[335]\n",
    "_Schuh_1 = data_Schuh_1.get(\"voxels\")[335]\n",
    "_Schuh_2 = data_Schuh_2.get(\"voxels\")[335]\n",
    "_Karton = data_Karton.get(\"voxels\")[335]\n",
    "_Innenvolumen_1 = data_Innenvolumen_1.get(\"voxels\")[335]\n",
    "_Innenvolumen_2 = data_Innenvolumen_2.get(\"voxels\")[335]\n",
    "_Obermaterial = data_Obermaterial.get(\"voxels\")[335]\n",
    "_Innensohle = data_Innensohle.get(\"voxels\")[335]\n",
    "_Aussensohle = data_Aussensohle.get(\"voxels\")[335]\n",
    "_Fuellmaterial = data_Fuellmaterial.get(\"voxels\")[335]\n",
    "_Zunge = data_Zunge.get(\"voxels\")[335]\n",
    "_Dummyschuh = data_Dummyschuh.get(\"voxels\")[335]\n",
    "\n",
    "image = np.stack((_Background, _Schuh_1, _Schuh_2, _Karton, _Innenvolumen_1, _Innenvolumen_2, _Obermaterial, _Innensohle, _Aussensohle, _Fuellmaterial, _Zunge, _Dummyschuh), axis=2)\n",
    "\n",
    "combinePictures(target_directory, \"Layer_335\", image.transpose(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image and masks for layer xyz of all shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImageLayer(folderpath, filename, volume, layer):\n",
    "\n",
    "    N = 1 # remove N pixels from the border\n",
    "\n",
    "    folder_path = Path(folderpath)\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    vol = volume[layer]\n",
    "\n",
    "    vol_values = np.unique(vol)\n",
    "    vol_max = vol_values[-1] # higest value\n",
    "    vol_min = vol_values[1] # second lowest ...\n",
    "\n",
    "    if np.issubdtype(vol.dtype, np.integer):\n",
    "        vol_max = vol.max()\n",
    "        vol_min = vol.min()\n",
    "\n",
    "    print(vol.shape, vol_max, vol_min, vol.max(), vol.min())\n",
    "\n",
    "    # Remove N pixels from the border because some are black even when the image is very bright; otherwise normalization (min/max) give not so good results \n",
    "    #vol = vol[N:-N, N:-N]\n",
    "\n",
    "    # Normalize the volume data to the range 0-255\n",
    "    normalized_volume = (vol - vol_min) / (vol_max - vol_min + 1e-5) * 255\n",
    "    normalized_volume = normalized_volume.astype(np.uint8)\n",
    "\n",
    "\n",
    "    # Save the image using PIL\n",
    "    image = Image.fromarray(normalized_volume)\n",
    "    #image = image.convert(\"L\")\n",
    "    image.save(f\"{folder_path.joinpath(filename)}_layer_{layer}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_directory = \"./images/images_2D/images\"\n",
    " \n",
    "# Create a dictionary of files and corresponding layers (layer were selected by visual inspection of all files)\n",
    "files_layers_dict = {\"./Data/volumes/Adidas_Martin-weiss.rek\": 287, \"./Data/volumes/Adidas_Martin.rek\": 494, \n",
    "                     \"./Data/volumes/Bruschi_down2_2_2.rek\": 217, \"./Data/volumes/Camper_down2_2_2.rek\": 141, \n",
    "                     \"./Data/volumes/Citywalk-sit-taupe-34_down2_2_2.rek\": 533, \"./Data/volumes/Citywalk-sit-taupe-36_down2_2_2.rek\": 535, \n",
    "                     \"./Data/volumes/Citywalk-sit-taupe-39_down2_2_2.rek\": 509, \"./Data/volumes/Citywalk-sit-taupe-40_down2_2_2.rek\": 489, \n",
    "                     \"./Data/volumes/Citywalk-sit-taupe-42_down2_2_2.rek\": 466, \"./Data/volumes/Herrenschuh_43p5_down2_2_2.rek\": 249, \n",
    "                     \"./Data/volumes/Lidl_43_down2_2_2.rek\": 205, \"./Data/volumes/Lloyd_38_down2_2_2.rek\": 249, \n",
    "                     \"./Data/volumes/Lloyd_pink_down2_2_2.rek\": 209, \"./Data/volumes/Lloyd_weiss_down2_2_2.rek\": 168, \n",
    "                     \"./Data/volumes/McKinley_Anton_down2_2_2.rek\": 535, \"./Data/volumes/Mustang-Sch-Navy-Metalli-35_down2_2_2.rek\": 466, \n",
    "                     \"./Data/volumes/Mustang-Sch-Navy-Metalli-40_down2_2_2.rek\": 466, \"./Data/volumes/Mustang-Sch-Navy-Metalli_31_down2_2_2.rek\": 443, \n",
    "                     \"./Data/volumes/Mustang-Sch-Navy-Metalli_36_down2_2_2.rek\": 443, \"./Data/volumes/Mustang-Sch-Navy-Metalli_37_down2_2_2.rek\": 484, \n",
    "                     \"./Data/volumes/Pertolio-dunkelbraun_43_down2_2_2.rek\": 402, \"./Data/volumes/Petrolio-Sch-dunkelbraun_42_down2_2_2.rek\": 322, \n",
    "                     \"./Data/volumes/Petrolio-Sch-dunkelbraun_44_down2_2_2.rek\": 363, \"./Data/volumes/Petrolio-Sch-dunkelbraun_46_down2_2_2.rek\": 523, \n",
    "                     \"./Data/volumes/PetrolioSch-40-float_down2_2_2.rek\": 230, \"./Data/volumes/Puma_38_down2_2_2.rek\": 202, \n",
    "                     \"./Data/volumes/Puma_Silver_down2_2_2.rek\": 216, \"./Data/volumes/Puma_White_down2_2_2.rek\": 216, \n",
    "                     \"./Data/volumes/Schuh_Martin_down2_2_2.rek\": 453, \"./Data/volumes/Shoepassion_40_down2_2_2.rek\": 243, \n",
    "                     \"./Data/volumes/Shoepassion_45_down2_2_2.rek\": 176, \"./Data/volumes/Shoepassion_Herren_40_down2_2_2.rek\": 74, \n",
    "                     \"./Data/volumes/Sneaker_Dana_Nike.rek\": 222, \"./Data/volumes/Sneaker_Dana_Puma_Flyer.rek\": 204, \n",
    "                     \"./Data/volumes/Stiefel-XY_40_down2_2_2.rek\": 483, \"./Data/volumes/Tamaris-Pump-Schwarz-38_down2_2_2.rek\": 362, \n",
    "                     \"./Data/volumes/Tamaris-Pump-schwarz_36_down2_2_2.rek\": 402, \"./Data/volumes/Tamaris-Pump-Schwarz_39_down2_2_2.rek\": 364, \n",
    "                     \"./Data/volumes/Tamaris-Pump-schwarz_40_down2_2_2.rek\": 443, \"./Data/volumes/Tamaris-Pump-schwarz_42_down2_2_2.rek\": 404}\n",
    "\n",
    "# files_layers_dict = {\"./Data/volumes/Stiefel-XY_40_down2_2_2.rek\": 483}\n",
    "\n",
    "# Loop through the dictionary\n",
    "for file, layer in files_layers_dict.items():\n",
    "    # Get the file name without extension\n",
    "    file_path  = Path(file)\n",
    "    filename =  file_path.stem\n",
    "    print(filename)  \n",
    "\n",
    "    header, volume = rek2py(filepath=file, switch_order=True)\n",
    "\n",
    "    if Path(file) in rotate_shoes:\n",
    "        orientation = (1,2,0)\n",
    "    else:\n",
    "        orientation = (2,1,0)\n",
    "\n",
    "    extractImageLayer(target_directory, filename, volume.transpose(orientation), layer) # these shoes need different orientation / transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_layers_dict = {\"./Data/annotations/Adidas_Martin-weiss.seg.nrrd\": 287,  \"./Data/annotations/Adidas_Martin.seg.nrrd\": 494,\n",
    "                     \"./Data/annotations/Bruschi_down2_2_2.seg.nrrd\": 217, \"./Data/annotations/Camper_down2_2_2.seg.nrrd\": 141,\n",
    "                     \"./Data/annotations/Citywalk 34.seg.nrrd\": 533, \"./Data/annotations/Citywalk 36.seg.nrrd\": 535, \n",
    "                     \"./Data/annotations/Citywalk 39.seg.nrrd\": 509, \"./Data/annotations/Citywalk 40.seg.nrrd\": 489, \n",
    "                     \"./Data/annotations/Citywalk 42.seg.nrrd\": 466, \"./Data/annotations/Herrenschuh_43p5_down2_2_2.seg.nrrd\": 249,\n",
    "                     \"./Data/annotations/Lidl_43_down2_2_2.seg.nrrd\": 205, \"./Data/annotations/Lloyd_38_down2_2_2.seg.nrrd\": 249, \n",
    "                     \"./Data/annotations/Lloyd_pink_down2_2_2.seg.nrrd\": 209, \"./Data/annotations/Lloyd_weiss_down2_2_2.seg.nrrd\": 168,\n",
    "                     \"./Data/annotations/McKinley_Anton.seg.nrrd\": 535, \"./Data/annotations/Mustang 35.seg.nrrd\": 466,\n",
    "                     \"./Data/annotations/Mustang 40.seg.nrrd\": 466, \"./Data/annotations/Mustang 31.seg.nrrd\": 443,\n",
    "                     \"./Data/annotations/Mustang 36.seg.nrrd\": 443, \"./Data/annotations/Mustang 37.seg.nrrd\": 484,\n",
    "                     \"./Data/annotations/Petrolio 43.seg.nrrd\": 402, \"./Data/annotations/Petrolio 42.seg.nrrd\": 322,\n",
    "                     \"./Data/annotations/Petrolio 44.seg.nrrd\": 363, \"./Data/annotations/Petrolio 46.seg.nrrd\": 523,\n",
    "                     \"./Data/annotations/Petrolio 40.seg.nrrd\": 230, \"./Data/annotations/Puma_38_down2_2_2.seg.nrrd\": 202,\n",
    "                     \"./Data/annotations/Puma_Silver_down2_2_2.seg.nrrd\": 216, \"./Data/annotations/Puma_White_down2_2_2.seg.nrrd\": 216,\n",
    "                     \"./Data/annotations/Schuh_Martin_down2_2_2.seg.nrrd\": 453, \"./Data/annotations/Shoepassion_40_down2_2_2.seg.nrrd\": 243,\n",
    "                     \"./Data/annotations/Shoepassion_45_down2_2_2.seg.nrrd\": 176, \"./Data/annotations/Shoepassion_Herren_40_down2_2_2.seg.nrrd\": 74,\n",
    "                     \"./Data/annotations/Sneaker_Dana_Nike.seg.nrrd\": 222, \"./Data/annotations/Sneaker_Dana_Puma_Flyer.seg.nrrd\": 204,\n",
    "                     \"./Data/annotations/StiefelXY.seg.nrrd\": 483, \"./Data/annotations/TamarisPump 38.seg.nrrd\": 362,\n",
    "                     \"./Data/annotations/TamarisPump 36.seg.nrrd\": 402, \"./Data/annotations/TamarisPump 39.seg.nrrd\": 364,\n",
    "                     \"./Data/annotations/TamarisPump 40.seg.nrrd\": 443, \"./Data/annotations/TamarisPump 42.seg.nrrd\": 404}\n",
    "\n",
    "rotate_shoes = [\"./Data/annotations/Adidas_Martin.seg.nrrd\",\"./Data/annotations/Citywalk 34.seg.nrrd\", \n",
    "                \"./Data/annotations/Citywalk 36.seg.nrrd\", \"./Data/annotations/Citywalk 40.seg.nrrd\", \n",
    "                \"./Data/annotations/Schuh_Martin_down2_2_2.seg.nrrd\", \"./Data/annotations/Sneaker_Dana_Nike.seg.nrrd\", \n",
    "                \"./Data/annotations/Sneaker_Dana_Puma_Flyer.seg.nrrd\"]\n",
    "\n",
    "# masks_layers_dict = {\"./Data/annotations/StiefelXY.seg.nrrd\": 483}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMaskLayer(folderpath, filename, mask, volume, layer):\n",
    "\n",
    "    N = 1 # remove N pixels from the border\n",
    "\n",
    "    folder_path = Path(folderpath)\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    vol = volume[layer]\n",
    "\n",
    "    # Remove N pixels from the border because some are black even when the image is very bright; otherwise normalization (min/max) give not so good results  (unfortunately, not all images can be corrected ...)\n",
    "    #print(\"shape before: \", vol.shape)\n",
    "    #vol = vol[N:-N, N:-N]\n",
    "    #print(\"shape after: \", vol.shape)\n",
    "\n",
    "    # Normalize the volume data to the range 0-255\n",
    "    normalized_volume = (vol - vol.min()) / (vol.max() - vol.min() + 1e-5) * 255\n",
    "    normalized_volume = normalized_volume.astype(np.uint8)    \n",
    "\n",
    "    # Save the image using PIL\n",
    "    image = Image.fromarray(normalized_volume)\n",
    "    image.save(f\"{folder_path.joinpath(filename)}_{mask}_layer_{layer}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = \"./images/images_2D/masks\"\n",
    "\n",
    "# Loop through the dictionary\n",
    "for file, layer in masks_layers_dict.items():\n",
    "    # Get the file name without extension\n",
    "    file_path  = Path(file)\n",
    "    \n",
    "    if file_path.suffix:  # Check again if there's at least one suffix\n",
    "        filename =  file_path.stem\n",
    "\n",
    "        if file_path.suffix:  # Check again if there's at least one suffix\n",
    "            filename = filename.rsplit('.', 1)[0]  # Remove the last part after the last '.'\n",
    "    print(filename)  \n",
    "\n",
    "    segmentation_info = slicerio.read_segmentation(file)\n",
    "    segment_names = slicerio.segment_names(segmentation_info) # Get semgnet_names where 3D Slicer\n",
    "\n",
    "    dict_label = {}\n",
    "    segment_names_to_labels = []\n",
    "    for j, sn in enumerate(segment_names):\n",
    "        segment_names_to_labels.append((sn, j+1)) \n",
    "        if not segment_names_to_labels:\n",
    "            continue\n",
    "    \n",
    "    #print(segment_names_to_labels)\n",
    "\n",
    "\n",
    "    # Numbering according to Segmented labels of 3D Slicer\n",
    "    data_Obermaterial   = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Obermaterial\"][0]])\n",
    "    data_Innensohle     = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Innensohle\"][0]])\n",
    "    data_Aussensohle    = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Auensohle\"][0]])\n",
    "    data_Fuellmaterial  = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Fllmaterial\"][0]])\n",
    "    data_Zunge          = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Zunge\"][0]])\n",
    "    data_Karton         = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Karton\"][0]])\n",
    "\n",
    "    if file in rotate_shoes:\n",
    "        orientation = (1,0,2) # these shoes need different orientation / transpose\n",
    "    else:\n",
    "        orientation = (0,1,2) # normal orientation for all shoes\n",
    "    \n",
    "    extractMaskLayer(target_directory, filename, \"Obermaterial\", data_Obermaterial.get(\"voxels\").transpose(orientation), layer)\n",
    "    extractMaskLayer(target_directory, filename, \"Innensohle\", data_Innensohle.get(\"voxels\").transpose(orientation), layer)\n",
    "    extractMaskLayer(target_directory, filename, \"Außensohle\", data_Aussensohle.get(\"voxels\").transpose(orientation), layer)\n",
    "    extractMaskLayer(target_directory, filename, \"Füllmaterial\", data_Fuellmaterial.get(\"voxels\").transpose(orientation), layer)\n",
    "    extractMaskLayer(target_directory, filename, \"Zunge\", data_Zunge.get(\"voxels\").transpose(orientation), layer)\n",
    "    extractMaskLayer(target_directory, filename, \"Karton\", data_Karton.get(\"voxels\").transpose(orientation), layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf215",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
