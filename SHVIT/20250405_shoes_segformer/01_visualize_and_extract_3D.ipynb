{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# from zipfile import ZipFile\n",
    "\n",
    "# path = \"./PythonTools-3.7.0-py2.py3-none-any.whl\"\n",
    "# names = ZipFile(path).namelist()\n",
    "# pprint.pprint(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import slicerio # https://pypi.org/project/slicerio/\n",
    "\n",
    "from PythonTools.rek2py import rek2py\n",
    "# from PythonTools.raw2dicom import raw2dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_variable = \"../../../../../Documents/Python/shoes_segformer/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CONVS = 2\n",
    " \n",
    " \n",
    "MODELNAME = f\"SegFormer_shvit_{N_CONVS}conv\"\n",
    "SHVIT_SEGFORMER = False\n",
    "# MODELNAME = \"SegFormer\"\n",
    "# SHVIT_SEGFORMER = False\n",
    " \n",
    "NUM_LAYERS = 10\n",
    " \n",
    " \n",
    "# DEPTH, HEIGHT, WIDTH = 128, 128, 128\n",
    "# DEPTH, HEIGHT, WIDTH = 196, 196, 196\n",
    "DEPTH, HEIGHT, WIDTH = 224, 224, 224\n",
    "# DEPTH, HEIGHT, WIDTH = 256, 256, 256\n",
    "# DEPTH, HEIGHT, WIDTH = 272, 272, 272\n",
    "# DEPTH, HEIGHT, WIDTH = 288, 288, 288\n",
    "# DEPTH, HEIGHT, WIDTH = 336, 336, 336\n",
    "# DEPTH, HEIGHT, WIDTH = 464, 464, 464\n",
    "# DEPTH, HEIGHT, WIDTH = 480, 480, 480\n",
    "# DEPTH, HEIGHT, WIDTH = 512, 512, 512\n",
    " \n",
    "factor = 4\n",
    "if (SHVIT_SEGFORMER):\n",
    "    factor = 2**N_CONVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Adidas_Martin-weiss.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Adidas_Martin.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Bruschi_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Camper_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Citywalk-sit-taupe-34_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Citywalk-sit-taupe-36_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Citywalk-sit-taupe-39_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Citywalk-sit-taupe-40_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Citywalk-sit-taupe-42_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Herrenschuh_43p5_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Lidl_43_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Lloyd_38_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Lloyd_pink_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Lloyd_weiss_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/McKinley_Anton_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Mustang-Sch-Navy-Metalli-35_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Mustang-Sch-Navy-Metalli-40_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Mustang-Sch-Navy-Metalli_31_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Mustang-Sch-Navy-Metalli_36_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Mustang-Sch-Navy-Metalli_37_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Pertolio-dunkelbraun_43_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Petrolio-Sch-dunkelbraun_42_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Petrolio-Sch-dunkelbraun_44_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Petrolio-Sch-dunkelbraun_46_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/PetrolioSch-40-float_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Puma_38_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Puma_Silver_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Puma_White_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Schuh_Martin_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Shoepassion_40_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Shoepassion_45_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Shoepassion_Herren_40_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Sneaker_Dana_Nike.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Sneaker_Dana_Puma_Flyer.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Stiefel-XY_40_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Tamaris-Pump-Schwarz-38_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Tamaris-Pump-schwarz_36_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Tamaris-Pump-Schwarz_39_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Tamaris-Pump-schwarz_40_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Tamaris-Pump-schwarz_42_down2_2_2.rek')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_all_files(directory, ext):\n",
    "\n",
    "    directory_path = Path(directory)\n",
    "    # List all files in the directory and subdirectories\n",
    "    all_files = list(directory_path.rglob(ext))  \n",
    "\n",
    "    # Filter out directories\n",
    "    files = [file for file in all_files if file.is_file()]\n",
    "    return files\n",
    "\n",
    "\n",
    "# Example usage\n",
    "directory = path_variable + \"volumes/\"\n",
    "files = list_all_files(directory, \"*.rek\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Adidas_Martin.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Citywalk-sit-taupe-34_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Citywalk-sit-taupe-36_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Citywalk-sit-taupe-40_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Schuh_Martin_down2_2_2.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Sneaker_Dana_Nike.rek'),\n",
       " PosixPath('../../../../../Documents/Python/shoes_segformer/Data/volumes/Sneaker_Dana_Puma_Flyer.rek')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after run check how shoes are oriented in the box; repeat only the files where shoes are not displayed from the side - modify transpose\n",
    "rotate_shoes = [path_variable + \"volumes/Adidas_Martin.rek\",path_variable + \"volumes/Citywalk-sit-taupe-34_down2_2_2.rek\", \n",
    "                path_variable + \"volumes/Citywalk-sit-taupe-36_down2_2_2.rek\", path_variable + \"volumes/Citywalk-sit-taupe-40_down2_2_2.rek\", \n",
    "                path_variable + \"volumes/Schuh_Martin_down2_2_2.rek\", path_variable + \"volumes/Sneaker_Dana_Nike.rek\",\n",
    "                path_variable + \"volumes/Sneaker_Dana_Puma_Flyer.rek\"]\n",
    "\n",
    "# Convert to pathlib.Path objects\n",
    "rotate_shoes = [Path(folder) for folder in rotate_shoes]\n",
    "rotate_shoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "def resize_volume(volume, depth=DEPTH, height=HEIGHT, width=WIDTH, factor=1):\n",
    "    \n",
    "    (vol_depth, vol_height, vol_width) = volume.shape\n",
    "    \n",
    "    depth_factor = depth/vol_depth/factor\n",
    "    height_factor = height/vol_height/factor\n",
    "    width_factor = width/vol_width/factor\n",
    "    \n",
    "    print(\"xx\"*20, volume.shape)\n",
    "    print(\"xx\"*20, depth_factor, height_factor, width_factor)\n",
    "    \n",
    "    volume = ndimage.zoom(volume, (depth_factor, height_factor, width_factor), order=1)\n",
    "    print(\"xx\"*20, volume.shape)\n",
    "    \n",
    "    return volume\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adidas_Martin-weiss\n",
      "(993, 988, 988)\n"
     ]
    }
   ],
   "source": [
    "def saveVolumes(folder, files):\n",
    "    for file in files:\n",
    "        \n",
    "        # Get the file name without extension\n",
    "        file_path  = Path(file)\n",
    "        filename =  file_path.stem\n",
    "        print(filename)\n",
    "\n",
    "        # dicomdata = raw2dicom(image=volume, ezrt_header=header)\n",
    "        header, volume = rek2py(filepath=file, switch_order=True)\n",
    "        print(volume.shape)\n",
    "        \n",
    "        _min, _max = 1, 99\n",
    "        if \"PetrolioSch-40-float_down2_2_2\" in str(file):\n",
    "            _min, _max = 4, 99            \n",
    "        \n",
    "        values = volume.flatten()\n",
    "        vmin = np.percentile(values, _min)\n",
    "        vmax = np.percentile(values, _max)\n",
    "        \n",
    "        scale = (volume.astype(np.float64) - vmin)/(vmax-vmin + 1e-5)\n",
    "        scale = np.clip(scale, 0, 1).astype(np.float32)\n",
    "    \n",
    "        # createAnimation(filename, volume)\n",
    "        if file in rotate_shoes:\n",
    "            orientation = (1,2,0)\n",
    "        else:\n",
    "            orientation = (2,1,0)\n",
    "            \n",
    "        volume = scale.transpose(orientation)      \n",
    "        volume = resize_volume(volume)\n",
    "        \n",
    "        folder_path = Path(folder)\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "        file_path = f\"{folder_path.joinpath(filename)}\" #.npz\"\n",
    "        # np.savez_compressed(file_path, volume)\n",
    "        np.save(file_path, volume)\n",
    "    \n",
    "\n",
    "target_directory = f\"{path_variable}images_3d_{MODELNAME}_{DEPTH}x{HEIGHT}x{WIDTH}/volumes\"\n",
    "saveVolumes(target_directory, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"vscode\"\n",
    "\n",
    "\n",
    "def plotVolume(folder, file):\n",
    "    \n",
    "    # Get the file name without extension\n",
    "    file_path  = Path(file)\n",
    "    filename =  file_path.stem\n",
    "    print(filename)    \n",
    "    \n",
    "    # Load 3D numpy array\n",
    "    shoe_volume = np.load(f\"{path_variable}images_3d_{MODELNAME}_{DEPTH}x{HEIGHT}x{WIDTH}/volumes/{filename}.npy\")  # Ensure this is a (128,128,128) NumPy array\n",
    "\n",
    "    # Create the 3D grid\n",
    "    x, y, z = np.mgrid[:DEPTH, :HEIGHT, :WIDTH]\n",
    "\n",
    "    # Create the volume plot\n",
    "    fig = go.Figure(data=go.Volume(\n",
    "        x=x.flatten(),\n",
    "        y=y.flatten(),\n",
    "        z=z.flatten(),\n",
    "        value=shoe_volume.flatten().astype(np.float16),\n",
    "        opacity=0.1,  # Adjust for visibility\n",
    "        surface_count=30,  # Number of isosurfaces\n",
    "        colorscale=\"gray\"  # Set grayscale colormap\n",
    "    ))\n",
    "\n",
    "    # Show the figure\n",
    "    fig.update_layout(\n",
    "        width=1000,  # Set the width in pixels\n",
    "        height=1000,   # Set the height in pixels\n",
    "        scene=dict(\n",
    "            xaxis=dict(showbackground=False),\n",
    "            yaxis=dict(showbackground=False),\n",
    "            zaxis=dict(showbackground=False),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    filename = f\"plot_{DEPTH}x{HEIGHT}x{WIDTH}_{filename}.html\"\n",
    "    folder_path = Path(folder)\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = f\"{folder_path.joinpath(filename)}\"\n",
    "\n",
    "    print(file_path)\n",
    "    fig.write_html(file_path)\n",
    "    \n",
    "    \n",
    "plot_directory = f\"{path_variable}images_3d/plots\"\n",
    "volume_directory = f\"{path_variable}images_3d_{MODELNAME}_{DEPTH}x{HEIGHT}x{WIDTH}/volumes\"\n",
    "files = list_all_files(volume_directory, \"*.npy\")\n",
    "    \n",
    "# for file in files:\n",
    "#     plotVolume(plot_directory, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = path_variable + \"annotations/\"\n",
    "files = list_all_files(directory, \"*.seg.nrrd\")\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    # Get the file name without extension\n",
    "    file_path  = Path(file)\n",
    "    filename =  file_path.stem\n",
    "    print(filename)    \n",
    "\n",
    "    segmentation = slicerio.read_segmentation(str(file), skip_voxels=True)\n",
    "\n",
    "    number_of_segments = len(segmentation[\"segments\"])\n",
    "    print(f\"Number of segments: {number_of_segments}\")\n",
    "\n",
    "    segment_names = slicerio.segment_names(segmentation)\n",
    "    print(f\"Segment names: {', '.join(segment_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image and masks for layer xyz of all shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_shoes = [path_variable + \"annotations/Adidas_Martin.seg.nrrd\", path_variable + \"annotations/Citywalk 34.seg.nrrd\", \n",
    "                path_variable + \"annotations/Citywalk 36.seg.nrrd\", path_variable + \"annotations/Citywalk 40.seg.nrrd\", \n",
    "                path_variable + \"annotations/Schuh_Martin_down2_2_2.seg.nrrd\", path_variable + \"annotations/Sneaker_Dana_Nike.seg.nrrd\", \n",
    "                path_variable + \"annotations/Sneaker_Dana_Puma_Flyer.seg.nrrd\"]\n",
    "\n",
    "rotate_shoes = [Path(folder) for folder in rotate_shoes]\n",
    "\n",
    "class_dict = {\"Karton\": 1, \"Außensohle\": 2, \"Innensohle\": 3, \"Obermaterial\": 4, \"Zunge\": 5, \"Füllmaterial\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"Zunge\"\n",
    "class_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMask(folder, file):\n",
    "\n",
    "    segmentation_info = slicerio.read_segmentation(file)\n",
    "    segment_names = slicerio.segment_names(segmentation_info) # Get semgnet_names where 3D Slicer\n",
    "\n",
    "    segment_names_to_labels = []\n",
    "    for j, sn in enumerate(segment_names):\n",
    "        segment_names_to_labels.append((sn, j+1)) \n",
    "        if not segment_names_to_labels:\n",
    "            continue\n",
    "        \n",
    "    # Numbering according to Segmented labels of 3D Slicer\n",
    "    data_Karton         = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Karton\"][0]])\n",
    "    data_Aussensohle    = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Auensohle\"][0]])\n",
    "    data_Innensohle     = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Innensohle\"][0]])\n",
    "    data_Obermaterial   = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Obermaterial\"][0]])\n",
    "    data_Zunge          = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Zunge\"][0]])\n",
    "    data_Fuellmaterial  = slicerio.extract_segments(segmentation_info, [[item for item in segment_names_to_labels if item[0] == \"Fllmaterial\"][0]])\n",
    "\n",
    "    if file in rotate_shoes:\n",
    "        orientation = (1,0,2) # these shoes need different orientation / transpose\n",
    "    else:\n",
    "        orientation = (0,1,2) # normal orientation for all shoes\n",
    "            \n",
    "    print(orientation)\n",
    "    data_Karton        = data_Karton.get(\"voxels\").transpose(orientation)            \n",
    "    data_Aussensohle   = data_Aussensohle.get(\"voxels\").transpose(orientation)            \n",
    "    data_Obermaterial  = data_Obermaterial.get(\"voxels\").transpose(orientation)            \n",
    "    data_Innensohle    = data_Innensohle.get(\"voxels\").transpose(orientation)            \n",
    "    data_Zunge         = data_Zunge.get(\"voxels\").transpose(orientation)            \n",
    "    data_Fuellmaterial = data_Fuellmaterial.get(\"voxels\").transpose(orientation)            \n",
    "        \n",
    "    # print(np.unique(data_Karton))\n",
    "    # print(np.unique(data_Aussensohle))\n",
    "    # print(np.unique(data_Obermaterial))\n",
    "    # print(np.unique(data_Innensohle))\n",
    "    # print(np.unique(data_Zunge))\n",
    "    # print(np.unique(data_Fuellmaterial))\n",
    "    \n",
    "    data_Karton = resize_volume(data_Karton, factor=factor)\n",
    "    data_Aussensohle = resize_volume(data_Aussensohle, factor=factor)\n",
    "    data_Obermaterial = resize_volume(data_Obermaterial, factor=factor)\n",
    "    data_Innensohle = resize_volume(data_Innensohle, factor=factor)\n",
    "    data_Zunge = resize_volume(data_Zunge, factor=factor)\n",
    "    data_Fuellmaterial = resize_volume(data_Fuellmaterial, factor=factor)\n",
    "\n",
    "\n",
    "    # Create an empty volume filled with zeros\n",
    "    final_volume = np.zeros(data_Karton.shape, dtype=np.uint8)\n",
    "    final_volume[data_Karton>0] = class_dict[\"Karton\"]\n",
    "    final_volume[data_Aussensohle>0] = class_dict[\"Außensohle\"]\n",
    "    final_volume[data_Innensohle>0] = class_dict[\"Innensohle\"]\n",
    "    final_volume[data_Obermaterial>0] = class_dict[\"Obermaterial\"]\n",
    "    final_volume[data_Zunge>0] = class_dict[\"Zunge\"]\n",
    "    final_volume[data_Fuellmaterial>0] = class_dict[\"Füllmaterial\"]\n",
    "\n",
    "    print(final_volume.shape, np.unique(final_volume))\n",
    "    \n",
    "    \n",
    "    if file.suffix:  # Check again if there's at least one suffix\n",
    "        filename =  file.stem\n",
    "\n",
    "        if file.suffix:  # Check again if there's at least one suffix\n",
    "            filename = filename.rsplit('.', 1)[0]  # Remove the last part after the last '.'\n",
    "    print(filename)  \n",
    "    \n",
    "    folder_path = Path(folder)\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = f\"{folder_path.joinpath(filename)}\" #.npz\"\n",
    "    # np.savez_compressed(file_path, volume)\n",
    "    np.save(file_path, final_volume)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "# extract mask information  \n",
    "target_directory = f\"{path_variable}images_3d_{MODELNAME}_{DEPTH}x{HEIGHT}x{WIDTH}/masks\"\n",
    "annotation_directory = path_variable + \"annotations/\"\n",
    "\n",
    "files = list_all_files(annotation_directory, \"*.seg.nrrd\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    createMask(target_directory, file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch260",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
